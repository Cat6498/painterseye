{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralRendererExperiments2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMwUyDlwLy/yDtBesImusyN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cat6498/painterseye/blob/main/NeuralRendererExperiments2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17HMtEG9SZFW"
      },
      "source": [
        "# Experimenting with a neural renderer - part 2\n",
        "\n",
        "After trying out the approach by Nakano and LibreAI as an introduction, it's time to get into it - in this colab notebook I'll try the approach from [Stylized Neural Painter](https://jiupinjia.github.io/neuralpainter/), creating a dual-architecture (rasterization + shading) painter network and training it on brushstrokes generated on the fly by the renderer itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz2GNcK0cYwW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRNLbqW1Yd_N"
      },
      "source": [
        "First of all, clone the git repository into the content folder and cd into it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WBrlwoRSWaJ",
        "outputId": "8d2f37ce-64b5-4c97-d565-2c6037e3f6ac"
      },
      "source": [
        "!git clone https://github.com/jiupinjia/stylized-neural-painting.git "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylized-neural-painting'...\n",
            "remote: Enumerating objects: 198, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 198 (delta 29), reused 26 (delta 10), pack-reused 143\u001b[K\n",
            "Receiving objects: 100% (198/198), 3.63 MiB | 6.43 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzNPywtWc66k",
        "outputId": "7bbbda4a-41f2-47fd-a3ad-cb125afbc884"
      },
      "source": [
        "cd stylized-neural-painting"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylized-neural-painting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh3jID33cccV"
      },
      "source": [
        "Import the packages and files we'll need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx8GD7H0fpPl",
        "outputId": "3c89237a-84bf-4932-867d-6d40cd82c671"
      },
      "source": [
        "%pip install -U git+https://github.com/szagoruyko/pytorchviz.git@master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/szagoruyko/pytorchviz.git@master\n",
            "  Cloning https://github.com/szagoruyko/pytorchviz.git (to revision master) to /tmp/pip-req-build-urzhx7o7\n",
            "  Running command git clone -q https://github.com/szagoruyko/pytorchviz.git /tmp/pip-req-build-urzhx7o7\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz==0.0.2) (1.9.0+cu111)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz==0.0.2) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz==0.0.2) (3.7.4.3)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4991 sha256=370875f341f08226f8930d7a298336c8fd78539520c2cfa487416d7f2a5b0081\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oygz0c98/wheels/69/06/fd/652908d49c931cdcca96be3c727fb11ed777a3a62402210396\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACc9_4LcYbrF"
      },
      "source": [
        "# General imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "# Torch imports\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "# For visualisation purposes\n",
        "from torchviz import make_dot\n",
        "\n",
        "# Imports from Stylized Neural Renderer\n",
        "import utils\n",
        "import loss\n",
        "from networks import *\n",
        "import renderer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvKL7xYydL-p"
      },
      "source": [
        "Run on GPU if available, else on CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20RPPMexcmkp",
        "outputId": "dd0afb77-ef27-4c75-9b5f-d3d7c70f5cdf"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJlwUh7CzSN1"
      },
      "source": [
        "## The PainterTrainer\n",
        "\n",
        "The PainterTrainer class will be our neural renderer.\n",
        "\n",
        "It is composed of several parts.\n",
        "\n",
        "<br />\n",
        "\n",
        "#### Dataloaders\n",
        "Passed as argument when initialising the PainterTrainer, they're defined with\n",
        "    \n",
        "    > utils.get_renderer_loaders(args)\n",
        "    \n",
        "where the get_renderer_loaders() fn generates two datasets, one for training and one for validation.\n",
        "\n",
        "The datasets are two objects of the StrokeDataset class, that generates strokes through the Renderer's random_stroke_params() and draw_stroke() methods. \n",
        "\n",
        "get_renderer_loaders then creates a dictionary dataloaders = {'train' : Dataloader(train), 'val' : Dataloader(val)}.  \n",
        "\n",
        "<br />\n",
        "\n",
        "---\n",
        "#### Renderer\n",
        "\n",
        "The renderer param indicates which type of brush gets created (available are oilpaintbrush (default), markerpen, watercolor and rectangle) and influences the shape of the action vectors. For oilpaintbrush, it also uses some png images in greyscale to give brushstrokes a \"rougher\" texture.\n",
        "\n",
        "It has methods to create a canvas and to update it with the latest brushstroke, to create random strokes parameters (ground truth) and to generate stroke parameters according to the renderer (generated brushstrokes).\n",
        "\n",
        "It also has a method draw_stroke that calls private methods according to renderer type. These actually create the brushstroke with a serie of transformations on the vectors, and they all end with a normalised foreground and stroke_alpha_mat that are used to update the canvas.\n",
        "\n",
        "<br />\n",
        "\n",
        "---\n",
        "#### Network\n",
        "\n",
        "Decides which class of generator to instantiate based on net_G parameter.\n",
        "\n",
        " The suggested one is a zou-fusion-net, that is made of two parts:\n",
        "    \n",
        "* a DCGAN made of convolutional-transpose layers, batch norm layers, and ReLU activations - from Radford et. al., used to get the color of the brushstroke\n",
        "    \n",
        "* a PixelShuffleNet made of FC linear layers and convolutional layers, used to get the mask of the brushstroke (so this is the rasterisation network?)\n",
        "\n",
        "PixelShuffleNet from PyTorch: rearranges elements in a tensor of shape $(∗,C×r^2,H,W)$ to a tensor of shape $(∗,C,H×r,W×r)$ where $r$ is an upscale factor. This is useful for implementing efficient sub-pixel convolution with a stride of $1/r$.\n",
        "\n",
        "<br />\n",
        "\n",
        "---\n",
        "> Why do we need to set the gradient to 0?\n",
        "\n",
        "[From StackOverflow](https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "\n",
        "In PyTorch, for every mini-batch during the training phase, we need to explicitly set the gradients to zero before starting to do backpropragation (i.e., updation of Weights and biases) because PyTorch accumulates the gradients on subsequent backward passes. This is convenient while training RNNs. So, the default action has been set to accumulate (i.e. sum) the gradients on every loss.backward() call.\n",
        "\n",
        "Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly. Else the gradient would point in some other direction than the intended direction towards the minimum (or maximum, in case of maximization objectives)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj3Q5g3XdKbL"
      },
      "source": [
        "class PainterTrainer():\n",
        "\n",
        "  def __init__(self, args, dataloaders):\n",
        "    \n",
        "    # Define the dataloaders\n",
        "    self.dataloaders = dataloaders\n",
        "\n",
        "    # Create the Renderer\n",
        "    self.renderer = renderer.Renderer(renderer=args.renderer)\n",
        "\n",
        "    # Define the network structure and load it to the device\n",
        "    self.net_G = define_G(rdrr=self.renderer, netG=args.net_G).to(device)\n",
        "\n",
        "    # define learning rate\n",
        "    self.lr = args.lr\n",
        "\n",
        "    # define the Adam optimizer - extension of SGD, efficient also with noisy or sparse gradients \n",
        "    self.optimizer_G = optim.Adam(self.net_G.parameters(), lr=self.lr, betas=(0.9, 0.999))\n",
        "\n",
        "    # define the learning rate scheduler - from pytorch docs: decays the learning rate of each parameter group by gamma every step_size epochs\n",
        "    self.lr_scheduler_G = optim.lr_scheduler.StepLR(self.optimizer_G, step_size=100, gamma=0.1)\n",
        "\n",
        "    # define the loss functions - just a torch.mean operation\n",
        "    self._pxl_loss = loss.PixelLoss(p=2)\n",
        "\n",
        "    # define some other vars to record the training states\n",
        "    self.running_acc = []\n",
        "    self.epoch_acc = 0\n",
        "    self.best_val_acc = 0.0\n",
        "    self.best_epoch_id = 0\n",
        "    self.epoch_to_start = 0\n",
        "    self.max_num_epochs = args.max_num_epochs\n",
        "    self.G_pred_foreground = None\n",
        "    self.G_pred_alpha = None\n",
        "    self.batch = None\n",
        "    self.G_loss = None\n",
        "    self.is_training = False\n",
        "    self.batch_id = 0\n",
        "    self.epoch_id = 0\n",
        "    self.checkpoint_dir = args.checkpoint_dir\n",
        "    self.vis_dir = args.vis_dir\n",
        "\n",
        "    # still not clear what this is for\n",
        "    self.VAL_ACC = np.array([], np.float32)\n",
        "    if os.path.exists(os.path.join(self.checkpoint_dir, 'val_acc.npy')):\n",
        "        self.VAL_ACC = np.load(os.path.join(self.checkpoint_dir, 'val_acc.npy'))\n",
        "\n",
        "    # check (and create if it does not exist) model directory\n",
        "    if os.path.exists(self.checkpoint_dir) is False:\n",
        "        os.mkdir(self.checkpoint_dir)\n",
        "    if os.path.exists(self.vis_dir) is False:\n",
        "        os.mkdir(self.vis_dir)\n",
        "\n",
        "     # visualize model\n",
        "    if args.print_models:\n",
        "        self._visualize_models()\n",
        "\n",
        "\n",
        "  # visualize the model in graph form \n",
        "  def _visualize_models(self):\n",
        "      \n",
        "    data = next(iter(self.dataloaders['train']))\n",
        "    y = self.net_G(data['A'].to(device))\n",
        "    dot = make_dot(y[0].mean(), params=dict(self.net_G.named_parameters()), show_attrs=True, show_saved=True)\n",
        "    dot.render('G')\n",
        "\n",
        "\n",
        "  # This decreases learning rate\n",
        "  def _update_lr_schedulers(self):\n",
        "    self.lr_scheduler_G.step()\n",
        "\n",
        "\n",
        "  # Computes accuracy of predictions \n",
        "  def _compute_acc(self):\n",
        "    \n",
        "    # ground truths\n",
        "    target_foreground = self.gt_foreground.to(device).detach()\n",
        "    target_alpha_map = self.gt_alpha.to(device).detach()\n",
        "\n",
        "    # predictions\n",
        "    foreground = self.G_pred_foreground.detach()\n",
        "    alpha_map = self.G_pred_alpha.detach()\n",
        "\n",
        "    # Average peak signal-to-noise ratio \n",
        "    psnr1 = utils.cpt_batch_psnr(foreground, target_foreground, PIXEL_MAX=1.0)\n",
        "    psnr2 = utils.cpt_batch_psnr(alpha_map, target_alpha_map, PIXEL_MAX=1.0)\n",
        "    return (psnr1 + psnr2)/2.0\n",
        "\n",
        "\n",
        "  # Called a the start of training - running_acc stores the evolution of accuracy through the painting process\n",
        "  def _clear_cache(self):\n",
        "    self.running_acc = []\n",
        "\n",
        "\n",
        "  # From the batch, get the action vector, and feed it to the network to get prediction of foreground and alpha\n",
        "  def _forward_pass(self, batch):\n",
        "    self.batch = batch\n",
        "    z_in = batch['A'].to(device)\n",
        "    self.G_pred_foreground, self.G_pred_alpha = self.net_G(z_in)\n",
        "\n",
        "\n",
        "  # Get the ground truth for alpha and foreground and compute pixel loss of both of them \n",
        "  def _backward_G(self):\n",
        "\n",
        "    self.gt_foreground = self.batch['B'].to(device)\n",
        "    self.gt_alpha = self.batch['ALPHA'].to(device)\n",
        "\n",
        "    _, _, h, w = self.G_pred_alpha.shape\n",
        "    self.gt_foreground = torch.nn.functional.interpolate(self.gt_foreground, (h, w), mode='area')\n",
        "    self.gt_alpha = torch.nn.functional.interpolate(self.gt_alpha, (h, w), mode='area')\n",
        "\n",
        "    pixel_loss1 = self._pxl_loss(self.G_pred_foreground, self.gt_foreground)\n",
        "    pixel_loss2 = self._pxl_loss(self.G_pred_alpha, self.gt_alpha)\n",
        "    self.G_loss = 100 * (pixel_loss1 + pixel_loss2) / 2.0\n",
        "    self.G_loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "  \"\"\" Checkpoint methods \"\"\"\n",
        "\n",
        "  def _load_checkpoint(self):\n",
        "\n",
        "    if os.path.exists(os.path.join(self.checkpoint_dir, 'last_ckpt.pt')):\n",
        "        print('loading last checkpoint...')\n",
        "        # load the entire checkpoint\n",
        "        checkpoint = torch.load(os.path.join(self.checkpoint_dir, 'last_ckpt.pt'))\n",
        "\n",
        "        # update net_G states\n",
        "        self.net_G.load_state_dict(checkpoint['model_G_state_dict'])\n",
        "        self.optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
        "        self.lr_scheduler_G.load_state_dict(\n",
        "            checkpoint['exp_lr_scheduler_G_state_dict'])\n",
        "        self.net_G.to(device)\n",
        "\n",
        "        # update some other states\n",
        "        self.epoch_to_start = checkpoint['epoch_id'] + 1\n",
        "        self.best_val_acc = checkpoint['best_val_acc']\n",
        "        self.best_epoch_id = checkpoint['best_epoch_id']\n",
        "\n",
        "        print('Epoch_to_start = %d, Historical_best_acc = %.4f (at epoch %d)' %\n",
        "              (self.epoch_to_start, self.best_val_acc, self.best_epoch_id))\n",
        "        print()\n",
        "\n",
        "    else:\n",
        "        print('training from scratch...')\n",
        "\n",
        "\n",
        "  def _save_checkpoint(self, ckpt_name):\n",
        "    torch.save({\n",
        "      'epoch_id': self.epoch_id,\n",
        "      'best_val_acc': self.best_val_acc,\n",
        "      'best_epoch_id': self.best_epoch_id,\n",
        "      'model_G_state_dict': self.net_G.state_dict(),\n",
        "      'optimizer_G_state_dict': self.optimizer_G.state_dict(),\n",
        "      'exp_lr_scheduler_G_state_dict': self.lr_scheduler_G.state_dict()\n",
        "    }, os.path.join(self.checkpoint_dir, ckpt_name))\n",
        "\n",
        "  \n",
        "  def _update_checkpoints(self):\n",
        "\n",
        "    # save current model\n",
        "    self._save_checkpoint(ckpt_name='last_ckpt.pt')\n",
        "    print('Lastest model updated. Epoch_acc=%.4f, Historical_best_acc=%.4f (at epoch %d)'\n",
        "          % (self.epoch_acc, self.best_val_acc, self.best_epoch_id))\n",
        "    print()\n",
        "\n",
        "    self.VAL_ACC = np.append(self.VAL_ACC, [self.epoch_acc])\n",
        "    np.save(os.path.join(self.checkpoint_dir, 'val_acc.npy'), self.VAL_ACC)\n",
        "\n",
        "    # update the best model (based on eval acc)\n",
        "    if self.epoch_acc > self.best_val_acc:\n",
        "        self.best_val_acc = self.epoch_acc\n",
        "        self.best_epoch_id = self.epoch_id\n",
        "        self._save_checkpoint(ckpt_name='best_ckpt.pt')\n",
        "        print('*' * 10 + 'Best model updated!')\n",
        "        print()\n",
        "\n",
        "\n",
        "\n",
        "  \"\"\" Batch analysis section \"\"\"\n",
        "\n",
        "  def _collect_running_batch_states(self):\n",
        "    self.running_acc.append(self._compute_acc().item())\n",
        "\n",
        "    m = len(self.dataloaders['train'])\n",
        "    if self.is_training is False:\n",
        "        m = len(self.dataloaders['val'])\n",
        "\n",
        "    # Every 100 batches print the state of training\n",
        "    if np.mod(self.batch_id, 100) == 1:\n",
        "        print('Is_training: %s. [%d,%d][%d,%d], G_loss: %.5f, running_acc: %.5f'\n",
        "              % (self.is_training, self.epoch_id, self.max_num_epochs-1, self.batch_id, m,\n",
        "                 self.G_loss.item(), np.mean(self.running_acc)))\n",
        "\n",
        "    # Every 1000 batches save a picture of the brushstroke in the visualisation directory\n",
        "    if np.mod(self.batch_id, 1000) == 1:\n",
        "        vis_pred_foreground = utils.make_numpy_grid(self.G_pred_foreground)\n",
        "        vis_gt_foreground = utils.make_numpy_grid(self.gt_foreground)\n",
        "        vis_pred_alpha = utils.make_numpy_grid(self.G_pred_alpha)\n",
        "        vis_gt_alpha = utils.make_numpy_grid(self.gt_alpha)\n",
        "\n",
        "        vis = np.concatenate([vis_pred_foreground, vis_gt_foreground,\n",
        "                              vis_pred_alpha, vis_gt_alpha], axis=0)\n",
        "        vis = np.clip(vis, a_min=0.0, a_max=1.0)\n",
        "        file_name = os.path.join(\n",
        "            self.vis_dir, 'istrain_'+str(self.is_training)+'_'+\n",
        "                          str(self.epoch_id)+'_'+str(self.batch_id)+'.jpg')\n",
        "        plt.imsave(file_name, vis)\n",
        "\n",
        "\n",
        "  def _collect_epoch_states(self):\n",
        "    # Get accuracy of epoch as mean of the various batches accuracies\n",
        "    self.epoch_acc = np.mean(self.running_acc)\n",
        "    print('Is_training: %s. Epoch %d / %d, epoch_acc= %.5f' %\n",
        "          (self.is_training, self.epoch_id, self.max_num_epochs-1, self.epoch_acc))\n",
        "    print()\n",
        "\n",
        "  \"\"\" Training section \"\"\"\n",
        "  def train_models(self):\n",
        "\n",
        "    self._load_checkpoint()\n",
        "\n",
        "    # loop over the epochs\n",
        "    for self.epoch_id in range(self.epoch_to_start, self.max_num_epochs):\n",
        "\n",
        "        self._clear_cache() # Reset the accuracy for the epoch\n",
        "        self.is_training = True\n",
        "        self.net_G.train()  # Set model to training mode\n",
        "        # Iterate over data\n",
        "        for self.batch_id, batch in enumerate(self.dataloaders['train'], 0):\n",
        "            # Take a step forward (sample ground truth), set the gradient to 0, take a step backwards (predict generated brushstrokes), and have the optimizer step\n",
        "            self._forward_pass(batch)\n",
        "            self.optimizer_G.zero_grad()\n",
        "            self._backward_G()\n",
        "            self.optimizer_G.step()\n",
        "        \n",
        "            self._collect_running_batch_states() # Get batch accuracy and print state\n",
        "        self._collect_epoch_states() # Get epoch accuracy and print the state\n",
        "        self._update_lr_schedulers() \n",
        "        self._update_checkpoints()\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H-PF0AX8RHS"
      },
      "source": [
        "parser = argparse.ArgumentParser(description='STYLIZED NEURAL PAINTING EXPERIMENT')\n",
        "parser.add_argument('-f')\n",
        "parser.add_argument('--renderer', type=str, default='oilpaintbrush', metavar='str',\n",
        "                    help='renderer: [watercolor, markerpen, oilpaintbrush, rectangle'\n",
        "                         'bezier, circle, square, rectangle] (default ...)')\n",
        "parser.add_argument('--batch_size', type=int, default=64, metavar='N',\n",
        "                    help='input batch size for training (default: 4)')\n",
        "parser.add_argument('--print_models', action='store_true', default=True,\n",
        "                    help='visualize and print networks')\n",
        "parser.add_argument('--net_G', type=str, default='zou-fusion-net', metavar='str',\n",
        "                    help='net_G: plain-dcgan or plain-unet or huang-net,'\n",
        "                         'zou-fusion-net, or zou-fusion-net-light')\n",
        "parser.add_argument('--checkpoint_dir', type=str, default=r'./checkpoints_G', metavar='str',\n",
        "                    help='dir to save checkpoints (default: ...)')\n",
        "parser.add_argument('--vis_dir', type=str, default=r'./val_out_G', metavar='str',\n",
        "                    help='dir to save results during training (default: ./val_out_G)')\n",
        "parser.add_argument('--lr', type=float, default=2e-4,\n",
        "                    help='learning rate (default: 0.0002)')\n",
        "parser.add_argument('--max_num_epochs', type=int, default=400, metavar='N',\n",
        "                    help='max number of training epochs (default 400)')\n",
        "args = parser.parse_args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCG__U86sOC1"
      },
      "source": [
        "# set parameters here\n",
        "args.renderer = 'oilpaintbrush'\n",
        "args.batch_size = 64\n",
        "args.print_models = True\n",
        "args.net_G = 'zou-fusion-net'\n",
        "args.checkpoint_dir = './checkpoints_G' \n",
        "args.vis_dir = './val_out_G'\n",
        "args.max_num_epochs = 100 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VdwbAaUE8a0A",
        "outputId": "e7066f09-feff-4a4a-cd78-2b2fa8ae01f5"
      },
      "source": [
        "dataloaders = utils.get_renderer_loaders(args)\n",
        "neurend = PainterTrainer(args=args, dataloaders=dataloaders)\n",
        "\n",
        "\"\"\" uncomment to get a visualisation of the generated ground truth\n",
        "# check if the data is loading correctly\n",
        "for i in range(10):\n",
        "    data = next(iter(dataloaders['train']))\n",
        "    vis_A = data['A']\n",
        "    vis_B = utils.make_numpy_grid(data['B'])\n",
        "    print(data['A'].cpu().numpy().shape[1])\n",
        "    print(data['B'].shape)\n",
        "    plt.imshow(vis_B)\n",
        "    plt.show()\n",
        "\"\"\"\n",
        "\n",
        "neurend.train_models()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize network with normal\n",
            "training from scratch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is_training: True. [0,99][1,782], G_loss: 7.07903, running_acc: 12.54427\n",
            "Is_training: True. [0,99][101,782], G_loss: 5.11373, running_acc: 13.42278\n",
            "Is_training: True. [0,99][201,782], G_loss: 3.36970, running_acc: 14.10678\n",
            "Is_training: True. [0,99][301,782], G_loss: 2.35786, running_acc: 14.88400\n",
            "Is_training: True. [0,99][401,782], G_loss: 2.22355, running_acc: 15.44160\n",
            "Is_training: True. [0,99][501,782], G_loss: 1.87427, running_acc: 15.88997\n",
            "Is_training: True. [0,99][601,782], G_loss: 1.98127, running_acc: 16.19803\n",
            "Is_training: True. [0,99][701,782], G_loss: 1.90482, running_acc: 16.45129\n",
            "Is_training: True. Epoch 0 / 99, epoch_acc= 16.60447\n",
            "\n",
            "Lastest model updated. Epoch_acc=16.6045, Historical_best_acc=0.0000 (at epoch 0)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [1,99][1,782], G_loss: 1.89106, running_acc: 18.02141\n",
            "Is_training: True. [1,99][101,782], G_loss: 1.91276, running_acc: 18.17191\n",
            "Is_training: True. [1,99][201,782], G_loss: 1.84537, running_acc: 18.21649\n",
            "Is_training: True. [1,99][301,782], G_loss: 1.95967, running_acc: 18.26976\n",
            "Is_training: True. [1,99][401,782], G_loss: 1.65318, running_acc: 18.29466\n",
            "Is_training: True. [1,99][501,782], G_loss: 1.81398, running_acc: 18.35056\n",
            "Is_training: True. [1,99][601,782], G_loss: 1.46652, running_acc: 18.39680\n",
            "Is_training: True. [1,99][701,782], G_loss: 1.56318, running_acc: 18.43172\n",
            "Is_training: True. Epoch 1 / 99, epoch_acc= 18.46344\n",
            "\n",
            "Lastest model updated. Epoch_acc=18.4634, Historical_best_acc=16.6045 (at epoch 0)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [2,99][1,782], G_loss: 1.58092, running_acc: 18.75401\n",
            "Is_training: True. [2,99][101,782], G_loss: 1.77360, running_acc: 18.76179\n",
            "Is_training: True. [2,99][201,782], G_loss: 1.74323, running_acc: 18.82970\n",
            "Is_training: True. [2,99][301,782], G_loss: 1.60593, running_acc: 18.92372\n",
            "Is_training: True. [2,99][401,782], G_loss: 1.30414, running_acc: 19.00700\n",
            "Is_training: True. [2,99][501,782], G_loss: 1.25914, running_acc: 19.09211\n",
            "Is_training: True. [2,99][601,782], G_loss: 1.48920, running_acc: 19.17120\n",
            "Is_training: True. [2,99][701,782], G_loss: 1.19429, running_acc: 19.24711\n",
            "Is_training: True. Epoch 2 / 99, epoch_acc= 19.31567\n",
            "\n",
            "Lastest model updated. Epoch_acc=19.3157, Historical_best_acc=18.4634 (at epoch 1)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [3,99][1,782], G_loss: 1.29954, running_acc: 19.89332\n",
            "Is_training: True. [3,99][101,782], G_loss: 1.19985, running_acc: 20.02122\n",
            "Is_training: True. [3,99][201,782], G_loss: 1.19041, running_acc: 20.16533\n",
            "Is_training: True. [3,99][301,782], G_loss: 1.00046, running_acc: 20.28419\n",
            "Is_training: True. [3,99][401,782], G_loss: 1.10939, running_acc: 20.36043\n",
            "Is_training: True. [3,99][501,782], G_loss: 0.97644, running_acc: 20.46007\n",
            "Is_training: True. [3,99][601,782], G_loss: 0.97640, running_acc: 20.54826\n",
            "Is_training: True. [3,99][701,782], G_loss: 1.03061, running_acc: 20.63645\n",
            "Is_training: True. Epoch 3 / 99, epoch_acc= 20.69366\n",
            "\n",
            "Lastest model updated. Epoch_acc=20.6937, Historical_best_acc=19.3157 (at epoch 2)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [4,99][1,782], G_loss: 1.05026, running_acc: 21.04145\n",
            "Is_training: True. [4,99][101,782], G_loss: 0.86526, running_acc: 21.31059\n",
            "Is_training: True. [4,99][201,782], G_loss: 0.85003, running_acc: 21.38444\n",
            "Is_training: True. [4,99][301,782], G_loss: 0.84404, running_acc: 21.46958\n",
            "Is_training: True. [4,99][401,782], G_loss: 0.77127, running_acc: 21.54936\n",
            "Is_training: True. [4,99][501,782], G_loss: 0.73822, running_acc: 21.60066\n",
            "Is_training: True. [4,99][601,782], G_loss: 0.74540, running_acc: 21.64286\n",
            "Is_training: True. [4,99][701,782], G_loss: 0.67453, running_acc: 21.70707\n",
            "Is_training: True. Epoch 4 / 99, epoch_acc= 21.74494\n",
            "\n",
            "Lastest model updated. Epoch_acc=21.7449, Historical_best_acc=20.6937 (at epoch 3)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [5,99][1,782], G_loss: 0.82441, running_acc: 21.86754\n",
            "Is_training: True. [5,99][101,782], G_loss: 0.79937, running_acc: 22.18918\n",
            "Is_training: True. [5,99][201,782], G_loss: 0.80017, running_acc: 22.21346\n",
            "Is_training: True. [5,99][301,782], G_loss: 0.74871, running_acc: 22.25253\n",
            "Is_training: True. [5,99][401,782], G_loss: 0.74178, running_acc: 22.29660\n",
            "Is_training: True. [5,99][501,782], G_loss: 0.77415, running_acc: 22.31881\n",
            "Is_training: True. [5,99][601,782], G_loss: 0.70847, running_acc: 22.34688\n",
            "Is_training: True. [5,99][701,782], G_loss: 0.62329, running_acc: 22.36661\n",
            "Is_training: True. Epoch 5 / 99, epoch_acc= 22.38849\n",
            "\n",
            "Lastest model updated. Epoch_acc=22.3885, Historical_best_acc=21.7449 (at epoch 4)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [6,99][1,782], G_loss: 0.68282, running_acc: 22.77088\n",
            "Is_training: True. [6,99][101,782], G_loss: 0.72548, running_acc: 22.65597\n",
            "Is_training: True. [6,99][201,782], G_loss: 0.65205, running_acc: 22.73483\n",
            "Is_training: True. [6,99][301,782], G_loss: 0.62404, running_acc: 22.75589\n",
            "Is_training: True. [6,99][401,782], G_loss: 0.67323, running_acc: 22.80800\n",
            "Is_training: True. [6,99][501,782], G_loss: 0.61039, running_acc: 22.84152\n",
            "Is_training: True. [6,99][601,782], G_loss: 0.58992, running_acc: 22.83097\n",
            "Is_training: True. [6,99][701,782], G_loss: 0.68638, running_acc: 22.86591\n",
            "Is_training: True. Epoch 6 / 99, epoch_acc= 22.89444\n",
            "\n",
            "Lastest model updated. Epoch_acc=22.8944, Historical_best_acc=22.3885 (at epoch 5)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [7,99][1,782], G_loss: 0.63295, running_acc: 22.92768\n",
            "Is_training: True. [7,99][101,782], G_loss: 0.60998, running_acc: 23.02259\n",
            "Is_training: True. [7,99][201,782], G_loss: 0.56421, running_acc: 23.12094\n",
            "Is_training: True. [7,99][301,782], G_loss: 0.58404, running_acc: 23.15104\n",
            "Is_training: True. [7,99][401,782], G_loss: 0.59423, running_acc: 23.18425\n",
            "Is_training: True. [7,99][501,782], G_loss: 0.61431, running_acc: 23.18258\n",
            "Is_training: True. [7,99][601,782], G_loss: 0.60793, running_acc: 23.22477\n",
            "Is_training: True. [7,99][701,782], G_loss: 0.55901, running_acc: 23.26030\n",
            "Is_training: True. Epoch 7 / 99, epoch_acc= 23.27908\n",
            "\n",
            "Lastest model updated. Epoch_acc=23.2791, Historical_best_acc=22.8944 (at epoch 6)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [8,99][1,782], G_loss: 0.50166, running_acc: 23.76926\n",
            "Is_training: True. [8,99][101,782], G_loss: 0.52685, running_acc: 23.49296\n",
            "Is_training: True. [8,99][201,782], G_loss: 0.46659, running_acc: 23.56483\n",
            "Is_training: True. [8,99][301,782], G_loss: 0.55068, running_acc: 23.62160\n",
            "Is_training: True. [8,99][401,782], G_loss: 0.51822, running_acc: 23.60219\n",
            "Is_training: True. [8,99][501,782], G_loss: 0.50666, running_acc: 23.64695\n",
            "Is_training: True. [8,99][601,782], G_loss: 0.54160, running_acc: 23.65374\n",
            "Is_training: True. [8,99][701,782], G_loss: 0.49289, running_acc: 23.68744\n",
            "Is_training: True. Epoch 8 / 99, epoch_acc= 23.69940\n",
            "\n",
            "Lastest model updated. Epoch_acc=23.6994, Historical_best_acc=23.2791 (at epoch 7)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [9,99][1,782], G_loss: 0.66979, running_acc: 23.19663\n",
            "Is_training: True. [9,99][101,782], G_loss: 0.43069, running_acc: 23.84351\n",
            "Is_training: True. [9,99][201,782], G_loss: 0.55958, running_acc: 23.87516\n",
            "Is_training: True. [9,99][301,782], G_loss: 0.52077, running_acc: 23.93903\n",
            "Is_training: True. [9,99][401,782], G_loss: 0.47935, running_acc: 23.96685\n",
            "Is_training: True. [9,99][501,782], G_loss: 0.46216, running_acc: 23.99204\n",
            "Is_training: True. [9,99][601,782], G_loss: 0.46736, running_acc: 23.99322\n",
            "Is_training: True. [9,99][701,782], G_loss: 0.48518, running_acc: 23.96241\n",
            "Is_training: True. Epoch 9 / 99, epoch_acc= 23.98633\n",
            "\n",
            "Lastest model updated. Epoch_acc=23.9863, Historical_best_acc=23.6994 (at epoch 8)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [10,99][1,782], G_loss: 0.45618, running_acc: 24.54697\n",
            "Is_training: True. [10,99][101,782], G_loss: 0.48565, running_acc: 24.20011\n",
            "Is_training: True. [10,99][201,782], G_loss: 0.45918, running_acc: 24.24010\n",
            "Is_training: True. [10,99][301,782], G_loss: 0.48383, running_acc: 24.22369\n",
            "Is_training: True. [10,99][401,782], G_loss: 0.44482, running_acc: 24.24000\n",
            "Is_training: True. [10,99][501,782], G_loss: 0.41470, running_acc: 24.25068\n",
            "Is_training: True. [10,99][601,782], G_loss: 0.42851, running_acc: 24.26492\n",
            "Is_training: True. [10,99][701,782], G_loss: 0.47248, running_acc: 24.27487\n",
            "Is_training: True. Epoch 10 / 99, epoch_acc= 24.29134\n",
            "\n",
            "Lastest model updated. Epoch_acc=24.2913, Historical_best_acc=23.9863 (at epoch 9)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [11,99][1,782], G_loss: 0.40996, running_acc: 24.46065\n",
            "Is_training: True. [11,99][101,782], G_loss: 0.48448, running_acc: 24.40726\n",
            "Is_training: True. [11,99][201,782], G_loss: 0.42011, running_acc: 24.45676\n",
            "Is_training: True. [11,99][301,782], G_loss: 0.42506, running_acc: 24.48318\n",
            "Is_training: True. [11,99][401,782], G_loss: 0.40267, running_acc: 24.49540\n",
            "Is_training: True. [11,99][501,782], G_loss: 0.49651, running_acc: 24.50903\n",
            "Is_training: True. [11,99][601,782], G_loss: 0.41887, running_acc: 24.49205\n",
            "Is_training: True. [11,99][701,782], G_loss: 0.39595, running_acc: 24.50107\n",
            "Is_training: True. Epoch 11 / 99, epoch_acc= 24.50889\n",
            "\n",
            "Lastest model updated. Epoch_acc=24.5089, Historical_best_acc=24.2913 (at epoch 10)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [12,99][1,782], G_loss: 0.44796, running_acc: 24.79291\n",
            "Is_training: True. [12,99][101,782], G_loss: 0.40201, running_acc: 24.47382\n",
            "Is_training: True. [12,99][201,782], G_loss: 0.43763, running_acc: 24.42282\n",
            "Is_training: True. [12,99][301,782], G_loss: 0.42451, running_acc: 24.50622\n",
            "Is_training: True. [12,99][401,782], G_loss: 0.39466, running_acc: 24.53287\n",
            "Is_training: True. [12,99][501,782], G_loss: 0.38753, running_acc: 24.53347\n",
            "Is_training: True. [12,99][601,782], G_loss: 0.39667, running_acc: 24.54742\n",
            "Is_training: True. [12,99][701,782], G_loss: 0.37382, running_acc: 24.56814\n",
            "Is_training: True. Epoch 12 / 99, epoch_acc= 24.58310\n",
            "\n",
            "Lastest model updated. Epoch_acc=24.5831, Historical_best_acc=24.5089 (at epoch 11)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [13,99][1,782], G_loss: 0.38729, running_acc: 24.95671\n",
            "Is_training: True. [13,99][101,782], G_loss: 0.38128, running_acc: 24.75754\n",
            "Is_training: True. [13,99][201,782], G_loss: 0.44597, running_acc: 24.74936\n",
            "Is_training: True. [13,99][301,782], G_loss: 0.42285, running_acc: 24.70332\n",
            "Is_training: True. [13,99][401,782], G_loss: 0.45308, running_acc: 24.68260\n",
            "Is_training: True. [13,99][501,782], G_loss: 0.44675, running_acc: 24.65853\n",
            "Is_training: True. [13,99][601,782], G_loss: 0.46131, running_acc: 24.67511\n",
            "Is_training: True. [13,99][701,782], G_loss: 0.40061, running_acc: 24.67890\n",
            "Is_training: True. Epoch 13 / 99, epoch_acc= 24.69452\n",
            "\n",
            "Lastest model updated. Epoch_acc=24.6945, Historical_best_acc=24.5831 (at epoch 12)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [14,99][1,782], G_loss: 0.38643, running_acc: 25.23189\n",
            "Is_training: True. [14,99][101,782], G_loss: 0.44502, running_acc: 24.92636\n",
            "Is_training: True. [14,99][201,782], G_loss: 0.40049, running_acc: 24.88754\n",
            "Is_training: True. [14,99][301,782], G_loss: 0.36757, running_acc: 24.85163\n",
            "Is_training: True. [14,99][401,782], G_loss: 0.37110, running_acc: 24.85675\n",
            "Is_training: True. [14,99][501,782], G_loss: 0.39002, running_acc: 24.82758\n",
            "Is_training: True. [14,99][601,782], G_loss: 0.38971, running_acc: 24.83441\n",
            "Is_training: True. [14,99][701,782], G_loss: 0.42493, running_acc: 24.84677\n",
            "Is_training: True. Epoch 14 / 99, epoch_acc= 24.87777\n",
            "\n",
            "Lastest model updated. Epoch_acc=24.8778, Historical_best_acc=24.6945 (at epoch 13)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [15,99][1,782], G_loss: 0.44715, running_acc: 24.78858\n",
            "Is_training: True. [15,99][101,782], G_loss: 0.44793, running_acc: 24.88615\n",
            "Is_training: True. [15,99][201,782], G_loss: 0.35532, running_acc: 24.90118\n",
            "Is_training: True. [15,99][301,782], G_loss: 0.40770, running_acc: 24.92319\n",
            "Is_training: True. [15,99][401,782], G_loss: 0.49763, running_acc: 24.90384\n",
            "Is_training: True. [15,99][501,782], G_loss: 0.34784, running_acc: 24.91591\n",
            "Is_training: True. [15,99][601,782], G_loss: 0.34229, running_acc: 24.93032\n",
            "Is_training: True. [15,99][701,782], G_loss: 0.38328, running_acc: 24.93760\n",
            "Is_training: True. Epoch 15 / 99, epoch_acc= 24.94728\n",
            "\n",
            "Lastest model updated. Epoch_acc=24.9473, Historical_best_acc=24.8778 (at epoch 14)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [16,99][1,782], G_loss: 0.37955, running_acc: 25.07247\n",
            "Is_training: True. [16,99][101,782], G_loss: 0.43430, running_acc: 25.12417\n",
            "Is_training: True. [16,99][201,782], G_loss: 0.37655, running_acc: 25.12893\n",
            "Is_training: True. [16,99][301,782], G_loss: 0.37446, running_acc: 25.10590\n",
            "Is_training: True. [16,99][401,782], G_loss: 0.37141, running_acc: 25.10159\n",
            "Is_training: True. [16,99][501,782], G_loss: 0.34330, running_acc: 25.10082\n",
            "Is_training: True. [16,99][601,782], G_loss: 0.40048, running_acc: 25.09628\n",
            "Is_training: True. [16,99][701,782], G_loss: 0.38813, running_acc: 25.08705\n",
            "Is_training: True. Epoch 16 / 99, epoch_acc= 25.08088\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.0809, Historical_best_acc=24.9473 (at epoch 15)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [17,99][1,782], G_loss: 0.37575, running_acc: 24.90536\n",
            "Is_training: True. [17,99][101,782], G_loss: 0.36232, running_acc: 24.98151\n",
            "Is_training: True. [17,99][201,782], G_loss: 0.36906, running_acc: 24.99116\n",
            "Is_training: True. [17,99][301,782], G_loss: 0.35940, running_acc: 25.04360\n",
            "Is_training: True. [17,99][401,782], G_loss: 0.36847, running_acc: 25.06495\n",
            "Is_training: True. [17,99][501,782], G_loss: 0.42158, running_acc: 25.08624\n",
            "Is_training: True. [17,99][601,782], G_loss: 0.38043, running_acc: 25.13384\n",
            "Is_training: True. [17,99][701,782], G_loss: 0.33535, running_acc: 25.15083\n",
            "Is_training: True. Epoch 17 / 99, epoch_acc= 25.15351\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.1535, Historical_best_acc=25.0809 (at epoch 16)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [18,99][1,782], G_loss: 0.40291, running_acc: 25.26961\n",
            "Is_training: True. [18,99][101,782], G_loss: 0.36831, running_acc: 25.22451\n",
            "Is_training: True. [18,99][201,782], G_loss: 0.36681, running_acc: 25.18098\n",
            "Is_training: True. [18,99][301,782], G_loss: 0.34036, running_acc: 25.20395\n",
            "Is_training: True. [18,99][401,782], G_loss: 0.38010, running_acc: 25.19302\n",
            "Is_training: True. [18,99][501,782], G_loss: 0.36127, running_acc: 25.17761\n",
            "Is_training: True. [18,99][601,782], G_loss: 0.35716, running_acc: 25.17553\n",
            "Is_training: True. [18,99][701,782], G_loss: 0.34124, running_acc: 25.17112\n",
            "Is_training: True. Epoch 18 / 99, epoch_acc= 25.18425\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.1843, Historical_best_acc=25.1535 (at epoch 17)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [19,99][1,782], G_loss: 0.39722, running_acc: 24.86744\n",
            "Is_training: True. [19,99][101,782], G_loss: 0.33511, running_acc: 25.19544\n",
            "Is_training: True. [19,99][201,782], G_loss: 0.36662, running_acc: 25.29722\n",
            "Is_training: True. [19,99][301,782], G_loss: 0.36257, running_acc: 25.26584\n",
            "Is_training: True. [19,99][401,782], G_loss: 0.37726, running_acc: 25.24507\n",
            "Is_training: True. [19,99][501,782], G_loss: 0.35365, running_acc: 25.25385\n",
            "Is_training: True. [19,99][601,782], G_loss: 0.40675, running_acc: 25.26036\n",
            "Is_training: True. [19,99][701,782], G_loss: 0.37134, running_acc: 25.25197\n",
            "Is_training: True. Epoch 19 / 99, epoch_acc= 25.25555\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.2556, Historical_best_acc=25.1843 (at epoch 18)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [20,99][1,782], G_loss: 0.43835, running_acc: 24.42560\n",
            "Is_training: True. [20,99][101,782], G_loss: 0.36473, running_acc: 25.00514\n",
            "Is_training: True. [20,99][201,782], G_loss: 0.38104, running_acc: 25.10335\n",
            "Is_training: True. [20,99][301,782], G_loss: 0.34162, running_acc: 25.18670\n",
            "Is_training: True. [20,99][401,782], G_loss: 0.37340, running_acc: 25.23994\n",
            "Is_training: True. [20,99][501,782], G_loss: 0.36656, running_acc: 25.25810\n",
            "Is_training: True. [20,99][601,782], G_loss: 0.34604, running_acc: 25.27501\n",
            "Is_training: True. [20,99][701,782], G_loss: 0.32422, running_acc: 25.27595\n",
            "Is_training: True. Epoch 20 / 99, epoch_acc= 25.27903\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.2790, Historical_best_acc=25.2556 (at epoch 19)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [21,99][1,782], G_loss: 0.38385, running_acc: 25.50488\n",
            "Is_training: True. [21,99][101,782], G_loss: 0.31562, running_acc: 25.46561\n",
            "Is_training: True. [21,99][201,782], G_loss: 0.37006, running_acc: 25.45231\n",
            "Is_training: True. [21,99][301,782], G_loss: 0.28495, running_acc: 25.44326\n",
            "Is_training: True. [21,99][401,782], G_loss: 0.36455, running_acc: 25.43601\n",
            "Is_training: True. [21,99][501,782], G_loss: 0.38962, running_acc: 25.40807\n",
            "Is_training: True. [21,99][601,782], G_loss: 0.35232, running_acc: 25.36014\n",
            "Is_training: True. [21,99][701,782], G_loss: 0.30538, running_acc: 25.37541\n",
            "Is_training: True. Epoch 21 / 99, epoch_acc= 25.37626\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.3763, Historical_best_acc=25.2790 (at epoch 20)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [22,99][1,782], G_loss: 0.36673, running_acc: 25.14909\n",
            "Is_training: True. [22,99][101,782], G_loss: 0.32625, running_acc: 25.47277\n",
            "Is_training: True. [22,99][201,782], G_loss: 0.32631, running_acc: 25.48076\n",
            "Is_training: True. [22,99][301,782], G_loss: 0.37849, running_acc: 25.47093\n",
            "Is_training: True. [22,99][401,782], G_loss: 0.35951, running_acc: 25.46047\n",
            "Is_training: True. [22,99][501,782], G_loss: 0.38278, running_acc: 25.44199\n",
            "Is_training: True. [22,99][601,782], G_loss: 0.36256, running_acc: 25.45048\n",
            "Is_training: True. [22,99][701,782], G_loss: 0.35657, running_acc: 25.44782\n",
            "Is_training: True. Epoch 22 / 99, epoch_acc= 25.45572\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.4557, Historical_best_acc=25.3763 (at epoch 21)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [23,99][1,782], G_loss: 0.44658, running_acc: 25.03247\n",
            "Is_training: True. [23,99][101,782], G_loss: 0.34968, running_acc: 25.24312\n",
            "Is_training: True. [23,99][201,782], G_loss: 0.33443, running_acc: 25.32396\n",
            "Is_training: True. [23,99][301,782], G_loss: 0.31965, running_acc: 25.40006\n",
            "Is_training: True. [23,99][401,782], G_loss: 0.37231, running_acc: 25.43692\n",
            "Is_training: True. [23,99][501,782], G_loss: 0.37383, running_acc: 25.38185\n",
            "Is_training: True. [23,99][601,782], G_loss: 0.31714, running_acc: 25.41868\n",
            "Is_training: True. [23,99][701,782], G_loss: 0.33971, running_acc: 25.41882\n",
            "Is_training: True. Epoch 23 / 99, epoch_acc= 25.43526\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.4353, Historical_best_acc=25.4557 (at epoch 22)\n",
            "\n",
            "Is_training: True. [24,99][1,782], G_loss: 0.38630, running_acc: 25.39044\n",
            "Is_training: True. [24,99][101,782], G_loss: 0.34385, running_acc: 25.23129\n",
            "Is_training: True. [24,99][201,782], G_loss: 0.31601, running_acc: 25.39005\n",
            "Is_training: True. [24,99][301,782], G_loss: 0.37802, running_acc: 25.43697\n",
            "Is_training: True. [24,99][401,782], G_loss: 0.38510, running_acc: 25.45962\n",
            "Is_training: True. [24,99][501,782], G_loss: 0.35788, running_acc: 25.46589\n",
            "Is_training: True. [24,99][601,782], G_loss: 0.32140, running_acc: 25.47603\n",
            "Is_training: True. [24,99][701,782], G_loss: 0.34380, running_acc: 25.47098\n",
            "Is_training: True. Epoch 24 / 99, epoch_acc= 25.47964\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.4796, Historical_best_acc=25.4557 (at epoch 22)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [25,99][1,782], G_loss: 0.35323, running_acc: 25.58846\n",
            "Is_training: True. [25,99][101,782], G_loss: 0.29549, running_acc: 25.43957\n",
            "Is_training: True. [25,99][201,782], G_loss: 0.32193, running_acc: 25.43224\n",
            "Is_training: True. [25,99][301,782], G_loss: 0.33025, running_acc: 25.48926\n",
            "Is_training: True. [25,99][401,782], G_loss: 0.30083, running_acc: 25.50844\n",
            "Is_training: True. [25,99][501,782], G_loss: 0.36278, running_acc: 25.52052\n",
            "Is_training: True. [25,99][601,782], G_loss: 0.31316, running_acc: 25.54275\n",
            "Is_training: True. [25,99][701,782], G_loss: 0.31179, running_acc: 25.54013\n",
            "Is_training: True. Epoch 25 / 99, epoch_acc= 25.55444\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.5544, Historical_best_acc=25.4796 (at epoch 24)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [26,99][1,782], G_loss: 0.34334, running_acc: 25.50226\n",
            "Is_training: True. [26,99][101,782], G_loss: 0.34353, running_acc: 25.55139\n",
            "Is_training: True. [26,99][201,782], G_loss: 0.33735, running_acc: 25.52576\n",
            "Is_training: True. [26,99][301,782], G_loss: 0.31425, running_acc: 25.54704\n",
            "Is_training: True. [26,99][401,782], G_loss: 0.40247, running_acc: 25.50994\n",
            "Is_training: True. [26,99][501,782], G_loss: 0.33366, running_acc: 25.53569\n",
            "Is_training: True. [26,99][601,782], G_loss: 0.32119, running_acc: 25.52340\n",
            "Is_training: True. [26,99][701,782], G_loss: 0.40537, running_acc: 25.50887\n",
            "Is_training: True. Epoch 26 / 99, epoch_acc= 25.52182\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.5218, Historical_best_acc=25.5544 (at epoch 25)\n",
            "\n",
            "Is_training: True. [27,99][1,782], G_loss: 0.33099, running_acc: 25.49339\n",
            "Is_training: True. [27,99][101,782], G_loss: 0.32630, running_acc: 25.68539\n",
            "Is_training: True. [27,99][201,782], G_loss: 0.35274, running_acc: 25.67951\n",
            "Is_training: True. [27,99][301,782], G_loss: 0.33753, running_acc: 25.69081\n",
            "Is_training: True. [27,99][401,782], G_loss: 0.31473, running_acc: 25.64146\n",
            "Is_training: True. [27,99][501,782], G_loss: 0.32746, running_acc: 25.64384\n",
            "Is_training: True. [27,99][601,782], G_loss: 0.32676, running_acc: 25.62625\n",
            "Is_training: True. [27,99][701,782], G_loss: 0.34334, running_acc: 25.62904\n",
            "Is_training: True. Epoch 27 / 99, epoch_acc= 25.64368\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.6437, Historical_best_acc=25.5544 (at epoch 25)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [28,99][1,782], G_loss: 0.31970, running_acc: 25.24113\n",
            "Is_training: True. [28,99][101,782], G_loss: 0.33531, running_acc: 25.73340\n",
            "Is_training: True. [28,99][201,782], G_loss: 0.33320, running_acc: 25.71259\n",
            "Is_training: True. [28,99][301,782], G_loss: 0.34883, running_acc: 25.65916\n",
            "Is_training: True. [28,99][401,782], G_loss: 0.36498, running_acc: 25.64541\n",
            "Is_training: True. [28,99][501,782], G_loss: 0.34956, running_acc: 25.65249\n",
            "Is_training: True. [28,99][601,782], G_loss: 0.31533, running_acc: 25.67826\n",
            "Is_training: True. [28,99][701,782], G_loss: 0.37116, running_acc: 25.67103\n",
            "Is_training: True. Epoch 28 / 99, epoch_acc= 25.66862\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.6686, Historical_best_acc=25.6437 (at epoch 27)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [29,99][1,782], G_loss: 0.33820, running_acc: 25.50082\n",
            "Is_training: True. [29,99][101,782], G_loss: 0.32953, running_acc: 25.63320\n",
            "Is_training: True. [29,99][201,782], G_loss: 0.33333, running_acc: 25.66574\n",
            "Is_training: True. [29,99][301,782], G_loss: 0.31777, running_acc: 25.65979\n",
            "Is_training: True. [29,99][401,782], G_loss: 0.41287, running_acc: 25.67140\n",
            "Is_training: True. [29,99][501,782], G_loss: 0.34421, running_acc: 25.69899\n",
            "Is_training: True. [29,99][601,782], G_loss: 0.32804, running_acc: 25.70947\n",
            "Is_training: True. [29,99][701,782], G_loss: 0.34472, running_acc: 25.71339\n",
            "Is_training: True. Epoch 29 / 99, epoch_acc= 25.71236\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.7124, Historical_best_acc=25.6686 (at epoch 28)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [30,99][1,782], G_loss: 0.37629, running_acc: 25.61327\n",
            "Is_training: True. [30,99][101,782], G_loss: 0.32501, running_acc: 25.59704\n",
            "Is_training: True. [30,99][201,782], G_loss: 0.34700, running_acc: 25.64411\n",
            "Is_training: True. [30,99][301,782], G_loss: 0.35802, running_acc: 25.60631\n",
            "Is_training: True. [30,99][401,782], G_loss: 0.31186, running_acc: 25.67176\n",
            "Is_training: True. [30,99][501,782], G_loss: 0.32656, running_acc: 25.69659\n",
            "Is_training: True. [30,99][601,782], G_loss: 0.36273, running_acc: 25.71185\n",
            "Is_training: True. [30,99][701,782], G_loss: 0.32985, running_acc: 25.72024\n",
            "Is_training: True. Epoch 30 / 99, epoch_acc= 25.72564\n",
            "\n",
            "Lastest model updated. Epoch_acc=25.7256, Historical_best_acc=25.7124 (at epoch 29)\n",
            "\n",
            "**********Best model updated!\n",
            "\n",
            "Is_training: True. [31,99][1,782], G_loss: 0.31152, running_acc: 26.08741\n",
            "Is_training: True. [31,99][101,782], G_loss: 0.28788, running_acc: 25.76108\n",
            "Is_training: True. [31,99][201,782], G_loss: 0.28873, running_acc: 25.82366\n",
            "Is_training: True. [31,99][301,782], G_loss: 0.33920, running_acc: 25.84796\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2588308d6a5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \"\"\"\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mneurend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-109ec2590eb9>\u001b[0m in \u001b[0;36mtrain_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-109ec2590eb9>\u001b[0m in \u001b[0;36m_backward_G\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_backward_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_foreground\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ALPHA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq0pMQHg9kEi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}